# Part 1 Visualizations Guide

This document describes all visualizations generated for the Part 1 report.

## Overview

After running the full experiment (`bash run_full_experiment.sh`), you will have **at least 4 different types of figures** suitable for the report:

1. **Training Curves** - Training process visualization
2. **Adversarial Examples** - Visual showcase of attack effectiveness
3. **Performance Comparison** - Quantitative robustness analysis
4. **Perturbation Statistics** - Statistical analysis of perturbations
5. **Class-wise Performance** - Per-class robustness analysis
6. **Parameter Sensitivity** - Hyperparameter effect analysis (optional)

---

## Figure 1: Training Curves

**File**: `results/training_curves.png`  
**Generated by**: `train.py` (automatically during training)  
**Type**: Training Process Visualization

**Description**:  
Shows training progress over epochs with two subplots:
- **Left**: Training and validation loss curves
- **Right**: Training and validation accuracy curves

**Use in Report**:  
- Demonstrates model convergence
- Shows training stability
- Validates that the model was properly trained

**Required**: Yes

---

## Figure 2: Adversarial Examples

**File**: `results/adversarial_examples.png`  
**Generated by**: `visualize.py`  
**Type**: Example Showcase

**Description**:  
Shows 5 diverse adversarial examples, each with three images:
- **Left**: Original image with true label and predicted label
- **Middle**: Adversarial image with true label and new predicted label (color-coded: red if attack successful, green if failed)
- **Right**: Amplified perturbation (×10) with L∞ norm value

**Use in Report**:  
- Visually demonstrates attack effectiveness
- Shows imperceptibility of perturbations
- Illustrates successful and failed attacks
- Required: At least 5 examples as per assignment

**Required**: Yes

---

## Figure 3: Performance Comparison

**File**: `results/performance_comparison.png`  
**Generated by**: `generate_all_visualizations.py`  
**Type**: Performance Analysis

**Description**:  
Bar chart comparing:
- Clean Accuracy (green bar)
- Adversarial Accuracy (red bar)

Also displays Attack Success Rate as text annotation.

**Use in Report**:  
- Quantifies robustness drop
- Shows attack effectiveness
- Easy to understand comparison

**Required**: Yes (recommended)

---

## Figure 4: Perturbation Statistics

**File**: `results/perturbation_statistics.png`  
**Generated by**: `generate_all_visualizations.py`  
**Type**: Statistical Analysis

**Description**:  
Two histograms showing distribution of:
- **Left**: L∞ norms of perturbations
- **Right**: L2 norms of perturbations

Both include mean value markers.

**Use in Report**:  
- Analyzes perturbation characteristics
- Shows perturbation magnitude distribution
- Validates that perturbations are within ε budget

**Required**: Yes (recommended)

---

## Figure 5: Class-wise Performance

**File**: `results/class_wise_performance.png`  
**Generated by**: `generate_all_visualizations.py`  
**Type**: Class Analysis

**Description**:  
Grouped bar chart showing:
- Clean accuracy per CIFAR-10 class (green)
- Adversarial accuracy per CIFAR-10 class (red)

**Use in Report**:  
- Identifies which classes are more vulnerable
- Shows class-specific robustness
- Provides insights into model behavior

**Required**: Yes (recommended)

---

## Figure 6: Parameter Sensitivity

**File**: `results/parameter_sensitivity_plot.png`  
**Generated by**: `generate_all_visualizations.py` (requires `--sensitivity` flag)  
**Type**: Parameter Analysis

**Description**:  
Two line plots showing:
- **Left**: Effect of epsilon (ε) values on adversarial accuracy
- **Right**: Effect of number of iterations on adversarial accuracy

**Use in Report**:  
- Shows how attack parameters affect results
- Demonstrates importance of parameter selection
- Provides analysis of Auto-PGD behavior

**Required**: No (optional but valuable if sensitivity analysis was run)

---

## How to Generate All Visualizations

### Automatic (Recommended)

All visualizations are automatically generated when running the full experiment:

```bash
bash run_full_experiment.sh
```

This will generate:
- Training curves (during training)
- Adversarial examples (after evaluation)
- All additional visualizations (after evaluation)

### Manual Generation

If you need to regenerate visualizations:

```bash
# 1. Training curves (generated during training)
python train.py --epochs 100 --save_dir ./models

# 2. Adversarial examples
python visualize.py \
    --results_path ./results/adversarial_samples.pth \
    --model_path ./models/best_model.pth \
    --num_examples 5 \
    --save_path ./results/adversarial_examples.png

# 3. All additional visualizations
python generate_all_visualizations.py \
    --results_dir ./results \
    --model_path ./models/best_model.pth
```

---

## Minimum Requirements for Report

According to the assignment, you need **at least 4 different types of figures**. The recommended set is:

1. ✅ **Training Curves** - Required
2. ✅ **Adversarial Examples** - Required (at least 5 examples)
3. ✅ **Performance Comparison** - Recommended
4. ✅ **Perturbation Statistics** - Recommended
5. ✅ **Class-wise Performance** - Recommended
6. ⭐ **Parameter Sensitivity** - Optional (if sensitivity analysis was performed)

---

## Figure Quality Tips

1. **High Resolution**: All figures are saved at 150 DPI, suitable for print
2. **Clear Labels**: All axes and titles are properly labeled
3. **Color Coding**: Consistent color scheme (green for clean/positive, red for adversarial/negative)
4. **Legends**: All plots include legends where necessary
5. **Grid Lines**: Grid lines added for better readability

---

## Verification

After generating all visualizations, verify they exist:

```bash
ls -lh results/*.png
```

Expected files:
- `training_curves.png` (~50-100 KB)
- `adversarial_examples.png` (~100-200 KB)
- `performance_comparison.png` (~40-60 KB)
- `perturbation_statistics.png` (~40-60 KB)
- `class_wise_performance.png` (~60-80 KB)
- `parameter_sensitivity_plot.png` (~40-60 KB) - if sensitivity analysis was run

---

**Last updated**: 2024

